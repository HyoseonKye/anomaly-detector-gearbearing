{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Medium.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMq3tGnmmLeNXc4S6Et1UxL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeungJooKim/anomaly-detector-gearbearing/blob/master/Medium.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdXKbVedZEkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from numpy.random import seed\n",
        "\n",
        "from keras.layers import Input, Dropout\n",
        "from keras.layers.core import Dense \n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras import regularizers\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHKO8NPWZlqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "df = pd.read_csv('/content/gdrive/My Drive/merged_dataset_BearingTest_2.csv.txt',index_col=[0])\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqN2J0AffjU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sNZTgKbfmPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.plot()\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBVZY4RmgG2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train = df['2004-02-12 11:02:39':'2004-02-13 23:52:39']\n",
        "dataset_test = df['2004-02-13 23:52:39':]\n",
        "\n",
        "dataset_train.shape, dataset_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ19-vCPgLDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train.plot()\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H15Idb_1gOoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_test.plot()\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-Y9db9mgQdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = preprocessing.MinMaxScaler()\n",
        "\n",
        "X_train = pd.DataFrame(scaler.fit_transform(dataset_train), \n",
        "                              columns=dataset_train.columns, \n",
        "                              index=dataset_train.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cLnCdEgghYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random shuffle training data\n",
        "X_train.sample(frac=1)\n",
        "\n",
        "X_test = pd.DataFrame(scaler.transform(dataset_test), \n",
        "                             columns=dataset_test.columns, \n",
        "                             index=dataset_test.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0V2YqoXgUyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.plot(figsize = (12,6))\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQNgf2sZgYxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.plot(figsize = (12,6))\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj8z95HZgksw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed(10)\n",
        "\n",
        "act_func = 'elu'\n",
        "print(X_train.shape[1])\n",
        "# Input layer:\n",
        "model=Sequential()\n",
        "\n",
        "# First hidden layer, connected to input vector X. \n",
        "model.add(Dense(10,activation=act_func,\n",
        "                kernel_initializer='glorot_uniform',\n",
        "                kernel_regularizer=regularizers.l2(0.0),\n",
        "                input_shape=(X_train.shape[1],)\n",
        "              \n",
        "               )\n",
        "         )\n",
        "\n",
        "# 2nd layer\n",
        "model.add(Dense(2,activation=act_func,\n",
        "                kernel_initializer='glorot_uniform'))\n",
        "\n",
        "# 3rd layer\n",
        "model.add(Dense(10,activation=act_func,\n",
        "                kernel_initializer='glorot_uniform'))\n",
        "\n",
        "model.add(Dense(X_train.shape[1],\n",
        "                kernel_initializer='glorot_uniform'))\n",
        "\n",
        "model.compile(loss='mse',optimizer='adam')\n",
        "\n",
        "# Train model for 100 epochs, batch size of 10: \n",
        "NUM_EPOCHS=100\n",
        "BATCH_SIZE=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCpfzBYvEkuc",
        "colab_type": "text"
      },
      "source": [
        "elu 활성화 함수 = 뉴럴 네트워크의 개별 뉴런에 들어오는 입력 신호의 총합을 출력 신호로 변환하는 함수."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2X7Hbpbgv7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y1IFSxZgyBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history=model.fit(np.array(X_train),np.array(X_train),\n",
        "                  batch_size=BATCH_SIZE, \n",
        "                  epochs=NUM_EPOCHS,\n",
        "                  validation_split=0.05,\n",
        "                  verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RiQphoWg2O_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize training/validation loss:\n",
        "plt.plot(history.history['loss'],\n",
        "         'b',\n",
        "         label='Training loss')\n",
        "plt.plot(history.history['val_loss'],\n",
        "         'r',\n",
        "         label='Validation loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss, [mse]')\n",
        "plt.ylim([0,.1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIxy97XTg7P3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_pred = model.predict(np.array(X_train))\n",
        "X_pred = pd.DataFrame(X_pred, \n",
        "                      columns=X_train.columns)\n",
        "X_pred.index = X_train.index\n",
        "\n",
        "scored = pd.DataFrame(index=X_train.index)\n",
        "scored['Loss_mae'] = np.mean(np.abs(X_pred-X_train), axis = 1)\n",
        "plt.figure()\n",
        "sns.distplot(scored['Loss_mae'],\n",
        "             bins = 10, \n",
        "             kde= True,\n",
        "            color = 'blue');\n",
        "plt.xlim([0.0,.5])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KqVfJUj1oWA",
        "colab_type": "text"
      },
      "source": [
        " 정상 작동하는 데이터들을 학습시킨 후 loss값 측정해 본 그래프. 이걸 통해 loss값의 기준치를 정할 수 있음. 그래프를 통해 loss값이 0.3 이상이면 비 정상으로 판단할 수 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0RLWW9LhNQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_pred = model.predict(np.array(X_test))\n",
        "X_pred = pd.DataFrame(X_pred, \n",
        "                      columns=X_test.columns)\n",
        "X_pred.index = X_test.index\n",
        "\n",
        "scored = pd.DataFrame(index=X_test.index)\n",
        "scored['Loss_mae'] = np.mean(np.abs(X_pred-X_test), axis = 1)\n",
        "scored['Threshold'] = 0.3\n",
        "scored['Anomaly'] = scored['Loss_mae'] > scored['Threshold']\n",
        "scored.head(10)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPnm816DhQdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scored.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV9vRgn7hSkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the same metrics also for the training set, and merge all data in a single dataframe:\n",
        "X_pred_train = model.predict(np.array(X_train))\n",
        "X_pred_train = pd.DataFrame(X_pred_train, \n",
        "                      columns=X_train.columns)\n",
        "X_pred_train.index = X_train.index\n",
        "\n",
        "scored_train = pd.DataFrame(index=X_train.index)\n",
        "scored_train['Loss_mae'] = np.mean(np.abs(X_pred_train-X_train), axis = 1)\n",
        "scored_train['Threshold'] = 0.3\n",
        "scored_train['Anomaly'] = scored_train['Loss_mae'] > scored_train['Threshold']\n",
        "print(scored)\n",
        "scored = pd.concat([scored_train, scored])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV5gK_xphg4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scored_train.Anomaly.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eHI8aS7f3Es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnXPBsUHhjAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scored.Anomaly.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhQhAtRWhk3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the model output in the time leading up to the bearing failure\n",
        "scored.plot(logy=True,  figsize = (10,6), ylim = [1e-2,1e2], color = ['blue','red'])\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}